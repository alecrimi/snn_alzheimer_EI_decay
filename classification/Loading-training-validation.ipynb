{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f099cc36-976e-4fde-a43b-2e63d8cd91f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import gc\n",
    "import gzip\n",
    "import numpy as np\n",
    "import mne\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.nn import Module, Linear , LayerNorm, BatchNorm1d, Dropout\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import networkx as nx\n",
    "from collections import Counter\n",
    "from snntorch import spikegen\n",
    "import warnings\n",
    "import random\n",
    "import pyarrow\n",
    "from snntorch import spikegen\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "import snntorch\n",
    "import imblearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from typing import Literal, Optional, Tuple\n",
    "import joblib\n",
    "\n",
    "mne.set_log_level(\"ERROR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95e355d2-c867-4edf-a6f4-445308b38bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_global_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.use_deterministic_algorithms(False, warn_only=True)\n",
    "    # torch.backends.cudnn.deterministic = True\n",
    "    # torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d0a376c-306e-4ef5-92e4-3f35e61246ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# SNN that consumes [T, B, F]\n",
    "# -----------------------------\n",
    "class SNNModel(nn.Module):\n",
    "    \"\"\"Spiking Neural Network that accepts spike trains shaped [T, B, F].\"\"\"\n",
    "    def __init__(self, input_size: int, hidden_size: int, output_size: int, beta: float = 0.5, num_steps: int = 25):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.lif1 = snn.Leaky(beta=beta, spike_grad=surrogate.fast_sigmoid())\n",
    "\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.lif2 = snn.Leaky(beta=beta, spike_grad=surrogate.fast_sigmoid())\n",
    "\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        self.lif3 = snn.Leaky(beta=beta, spike_grad=surrogate.fast_sigmoid())\n",
    "\n",
    "        self.num_steps = int(num_steps)\n",
    "\n",
    "    def forward(self, x_TBF: torch.Tensor):\n",
    "        assert x_TBF.dim() == 3, f\"Expected [T,B,F], got {tuple(x_TBF.shape)}\"\n",
    "        T, B, _ = x_TBF.shape\n",
    "        device = x_TBF.device\n",
    "\n",
    "        mem1 = torch.zeros(B, self.fc1.out_features, device=device)\n",
    "        mem2 = torch.zeros(B, self.fc2.out_features, device=device)\n",
    "        mem3 = torch.zeros(B, self.fc3.out_features, device=device)\n",
    "\n",
    "        spk3_rec, mem3_rec = [], []\n",
    "        for t in range(T):\n",
    "            x = x_TBF[t]                 # [B,F]\n",
    "            cur1 = self.fc1(x)           # [B,H]\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "\n",
    "            cur2 = self.fc2(spk1)        # [B,H]\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "\n",
    "            cur3 = self.fc3(spk2)        # [B,C]\n",
    "            spk3, mem3 = self.lif3(cur3, mem3)\n",
    "\n",
    "            spk3_rec.append(spk3)\n",
    "            mem3_rec.append(mem3)\n",
    "\n",
    "        return torch.stack(spk3_rec, 0), torch.stack(mem3_rec, 0)  # [T,B,C]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4c92c13-70ed-43c1-bdea-6ff74f6c5134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_to_spikes_eval(\n",
    "    x: torch.Tensor,          # [B,F] po scalerze\n",
    "    num_steps: int,\n",
    "    method: str = \"rate\",\n",
    "    gain: float = 0.3\n",
    ") -> torch.Tensor:\n",
    "    # MUSI BYĆ TAK SAMO jak w SNNTrainer._encode_to_spikes\n",
    "    # Zakładam wersję ze stabilnym skalowaniem:\n",
    "    x_norm = torch.sigmoid(x)      # 0–1, bez per-batch min/max\n",
    "\n",
    "    if method == \"rate\":\n",
    "        spikes = spikegen.rate(x_norm, num_steps=num_steps, gain=gain)\n",
    "    elif method == \"latency\":\n",
    "        spikes = spikegen.latency(x_norm, num_steps=num_steps, normalize=True)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown encoding method: {method}\")\n",
    "    return spikes\n",
    "\n",
    "@torch.no_grad()\n",
    "def infer_logits_batched(\n",
    "    model: torch.nn.Module,\n",
    "    X_float: torch.Tensor,              # [N,F] (już po scalerze)\n",
    "    batch_size: int = 128,\n",
    "    encoding_method: str = \"rate\",\n",
    "    num_steps: int | None = None,\n",
    "    device: str | torch.device = \"cpu\",\n",
    ") -> torch.Tensor:\n",
    "    model.eval().to(device)\n",
    "    X_float = X_float.to(device)\n",
    "    N = X_float.shape[0]\n",
    "    steps = int(num_steps or getattr(model, \"num_steps\", 25))\n",
    "\n",
    "    outs = []\n",
    "    for i in range(0, N, batch_size):\n",
    "        xb = X_float[i:i+batch_size]                      # [B,F]\n",
    "\n",
    "        spikes = encode_to_spikes_eval(\n",
    "            xb,\n",
    "            num_steps=steps,\n",
    "            method=encoding_method,\n",
    "        ).to(device)                                      # [T,B,F]\n",
    "\n",
    "        spk_rec, mem_rec = model(spikes)                  # [T,B,C]\n",
    "\n",
    "        if encoding_method == \"rate\":\n",
    "            out = spk_rec.sum(dim=0)                      # [B,C]\n",
    "        elif encoding_method == \"latency\":\n",
    "            out = mem_rec.max(dim=0).values               # [B,C]\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown encoding method: {encoding_method}\")\n",
    "\n",
    "        outs.append(out.detach().cpu())\n",
    "\n",
    "    return torch.cat(outs, dim=0)                         # [N,C]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3f26810-f11e-4607-ac14-c9ead0e2b6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "ALL_FEATURE_SETS = [\"katz\", \"bands_rel\", \"bands_abs\", \"f1_slope_calc_by_me\", \"f1_slope_calc_by_fooof\", \"plv\", \"mean_std\"]\n",
    "\n",
    "\n",
    "def _cache_paths(cache_prefix: str):\n",
    "    return {\n",
    "        \"X\":   f\"{cache_prefix}X.parquet\",\n",
    "        \"y\":   f\"{cache_prefix}y.parquet\",\n",
    "        \"meta\": f\"{cache_prefix}meta.parquet\",\n",
    "        \"chs\":  f\"{cache_prefix}channels.json\",\n",
    "        \"cfg\":  f\"{cache_prefix}config.json\",\n",
    "    }\n",
    "\n",
    "\n",
    "def load_extracted_features(\n",
    "    features, \n",
    "    cache_root: str = \"./cache/\"\n",
    "):\n",
    "    if isinstance(features, str):\n",
    "            feature_list = [features]\n",
    "    else:\n",
    "        feature_list = list(features)\n",
    "\n",
    "    if not feature_list:\n",
    "        raise ValueError(\"No features requested.\")\n",
    "\n",
    "    X_all = []\n",
    "    y_ser_ref = None\n",
    "    meta_ref = None\n",
    "    channels_ref = None\n",
    "    cfg_merged: dict = {}\n",
    "\n",
    "    for feat_name in feature_list:\n",
    "        sub_list = [feat_name]\n",
    "\n",
    "        for fn in sub_list:\n",
    "            cache_prefix = os.path.join(cache_root, fn, \"\")\n",
    "            paths = _cache_paths(cache_prefix)\n",
    "\n",
    "            missing = [k for k, p in paths.items() if k in (\"X\", \"y\", \"meta\") and not os.path.exists(p)]\n",
    "            if missing:\n",
    "                raise FileNotFoundError(\n",
    "                    f\"Missing cached files for feature '{fn}' in '{cache_prefix}': {missing}\"\n",
    "                )\n",
    "\n",
    "            print(f\"[cache] Loading features '{fn}' from '{cache_prefix}_*.parquet'\")\n",
    "\n",
    "            X_df  = pd.read_parquet(paths[\"X\"])\n",
    "            y_ser = pd.read_parquet(paths[\"y\"])[\"label\"]\n",
    "            meta  = pd.read_parquet(paths[\"meta\"])\n",
    "\n",
    "            # channels (optional)\n",
    "            if os.path.exists(paths[\"chs\"]):\n",
    "                with open(paths[\"chs\"], \"r\") as f:\n",
    "                    chs = json.load(f)\n",
    "            else:\n",
    "                chs = None\n",
    "\n",
    "            cfg_local = {}\n",
    "            if os.path.exists(paths[\"cfg\"]):\n",
    "                with open(paths[\"cfg\"], \"r\") as f:\n",
    "                    cfg_local = json.load(f)\n",
    "\n",
    "            if y_ser_ref is None:\n",
    "                y_ser_ref = y_ser\n",
    "                meta_ref  = meta\n",
    "                channels_ref = chs\n",
    "            else:\n",
    "                if len(y_ser) != len(y_ser_ref):\n",
    "                    raise ValueError(\n",
    "                        f\"Feature set '{fn}' has {len(y_ser)} samples, \"\n",
    "                        f\"but previous set has {len(y_ser_ref)}.\"\n",
    "                    )\n",
    "            X_df_prefixed = X_df.add_prefix(f\"{fn}__\")\n",
    "\n",
    "            X_all.append(X_df_prefixed)\n",
    "\n",
    "            cfg_merged.update(cfg_local)\n",
    "\n",
    "    if not X_all:\n",
    "        raise RuntimeError(\"No feature matrices were loaded; check 'features' and cache_root.\")\n",
    "\n",
    "    X_concat = pd.concat(X_all, axis=1)\n",
    "\n",
    "    print(f\"[cache] Final concatenated X shape: {X_concat.shape}\")\n",
    "    return X_concat, y_ser_ref, meta_ref, channels_ref, cfg_merged\n",
    "\n",
    "def _cache_paths(cache_prefix: str):\n",
    "    return {\n",
    "        \"X\": f\"{cache_prefix}X.parquet\",\n",
    "        \"y\": f\"{cache_prefix}y.parquet\",\n",
    "        \"meta\": f\"{cache_prefix}meta.parquet\",\n",
    "        \"chs\": f\"{cache_prefix}channels.json\",\n",
    "        \"cfg\": f\"{cache_prefix}config.json\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a0ce697-8e3a-43a0-add1-29cb6b943d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cache] Loading features 'f1_slope_calc_by_fooof' from './cache/f1_slope_calc_by_fooof/_*.parquet'\n",
      "[cache] Final concatenated X shape: (52552, 19)\n",
      "\n",
      "Preview X_df:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_slope_calc_by_fooof__fooof_f1_slope_C3</th>\n",
       "      <th>f1_slope_calc_by_fooof__fooof_f1_slope_C4</th>\n",
       "      <th>f1_slope_calc_by_fooof__fooof_f1_slope_Cz</th>\n",
       "      <th>f1_slope_calc_by_fooof__fooof_f1_slope_F3</th>\n",
       "      <th>f1_slope_calc_by_fooof__fooof_f1_slope_F4</th>\n",
       "      <th>f1_slope_calc_by_fooof__fooof_f1_slope_F7</th>\n",
       "      <th>f1_slope_calc_by_fooof__fooof_f1_slope_F8</th>\n",
       "      <th>f1_slope_calc_by_fooof__fooof_f1_slope_Fp1</th>\n",
       "      <th>f1_slope_calc_by_fooof__fooof_f1_slope_Fp2</th>\n",
       "      <th>f1_slope_calc_by_fooof__fooof_f1_slope_Fz</th>\n",
       "      <th>f1_slope_calc_by_fooof__fooof_f1_slope_O1</th>\n",
       "      <th>f1_slope_calc_by_fooof__fooof_f1_slope_O2</th>\n",
       "      <th>f1_slope_calc_by_fooof__fooof_f1_slope_P3</th>\n",
       "      <th>f1_slope_calc_by_fooof__fooof_f1_slope_P4</th>\n",
       "      <th>f1_slope_calc_by_fooof__fooof_f1_slope_Pz</th>\n",
       "      <th>f1_slope_calc_by_fooof__fooof_f1_slope_T3</th>\n",
       "      <th>f1_slope_calc_by_fooof__fooof_f1_slope_T4</th>\n",
       "      <th>f1_slope_calc_by_fooof__fooof_f1_slope_T5</th>\n",
       "      <th>f1_slope_calc_by_fooof__fooof_f1_slope_T6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.159743</td>\n",
       "      <td>1.680378</td>\n",
       "      <td>2.206824</td>\n",
       "      <td>1.709732</td>\n",
       "      <td>1.561775</td>\n",
       "      <td>1.748864</td>\n",
       "      <td>2.085033</td>\n",
       "      <td>1.406818</td>\n",
       "      <td>2.111207</td>\n",
       "      <td>1.721701</td>\n",
       "      <td>2.125500</td>\n",
       "      <td>2.083735</td>\n",
       "      <td>2.376242</td>\n",
       "      <td>1.939174</td>\n",
       "      <td>1.996931</td>\n",
       "      <td>1.551694</td>\n",
       "      <td>1.725685</td>\n",
       "      <td>2.056437</td>\n",
       "      <td>1.806958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.074079</td>\n",
       "      <td>2.131712</td>\n",
       "      <td>2.053111</td>\n",
       "      <td>1.639974</td>\n",
       "      <td>1.484552</td>\n",
       "      <td>1.865091</td>\n",
       "      <td>2.075424</td>\n",
       "      <td>1.535537</td>\n",
       "      <td>1.643439</td>\n",
       "      <td>1.879024</td>\n",
       "      <td>2.045097</td>\n",
       "      <td>2.077167</td>\n",
       "      <td>2.097744</td>\n",
       "      <td>2.083318</td>\n",
       "      <td>2.018160</td>\n",
       "      <td>1.818997</td>\n",
       "      <td>1.988955</td>\n",
       "      <td>2.066521</td>\n",
       "      <td>2.147957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.113567</td>\n",
       "      <td>2.265747</td>\n",
       "      <td>2.289503</td>\n",
       "      <td>1.675787</td>\n",
       "      <td>1.777413</td>\n",
       "      <td>2.115215</td>\n",
       "      <td>2.103583</td>\n",
       "      <td>1.611884</td>\n",
       "      <td>1.952839</td>\n",
       "      <td>2.041131</td>\n",
       "      <td>2.030921</td>\n",
       "      <td>2.158749</td>\n",
       "      <td>2.005443</td>\n",
       "      <td>2.240399</td>\n",
       "      <td>2.291582</td>\n",
       "      <td>1.927433</td>\n",
       "      <td>2.018851</td>\n",
       "      <td>1.901319</td>\n",
       "      <td>2.200489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.186963</td>\n",
       "      <td>2.379804</td>\n",
       "      <td>2.280436</td>\n",
       "      <td>1.509626</td>\n",
       "      <td>1.535515</td>\n",
       "      <td>1.883346</td>\n",
       "      <td>1.669940</td>\n",
       "      <td>1.504872</td>\n",
       "      <td>1.948231</td>\n",
       "      <td>1.960013</td>\n",
       "      <td>1.991852</td>\n",
       "      <td>2.038563</td>\n",
       "      <td>2.033714</td>\n",
       "      <td>2.051334</td>\n",
       "      <td>2.192498</td>\n",
       "      <td>2.055290</td>\n",
       "      <td>1.902660</td>\n",
       "      <td>1.941317</td>\n",
       "      <td>1.961843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.277863</td>\n",
       "      <td>2.539529</td>\n",
       "      <td>2.367014</td>\n",
       "      <td>1.712145</td>\n",
       "      <td>1.611813</td>\n",
       "      <td>2.106452</td>\n",
       "      <td>1.933161</td>\n",
       "      <td>1.927252</td>\n",
       "      <td>2.323573</td>\n",
       "      <td>2.080833</td>\n",
       "      <td>2.300203</td>\n",
       "      <td>2.282525</td>\n",
       "      <td>2.352912</td>\n",
       "      <td>2.373809</td>\n",
       "      <td>2.380740</td>\n",
       "      <td>2.283877</td>\n",
       "      <td>1.669275</td>\n",
       "      <td>2.264911</td>\n",
       "      <td>2.123244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f1_slope_calc_by_fooof__fooof_f1_slope_C3  \\\n",
       "0                                   2.159743   \n",
       "1                                   2.074079   \n",
       "2                                   2.113567   \n",
       "3                                   2.186963   \n",
       "4                                   2.277863   \n",
       "\n",
       "   f1_slope_calc_by_fooof__fooof_f1_slope_C4  \\\n",
       "0                                   1.680378   \n",
       "1                                   2.131712   \n",
       "2                                   2.265747   \n",
       "3                                   2.379804   \n",
       "4                                   2.539529   \n",
       "\n",
       "   f1_slope_calc_by_fooof__fooof_f1_slope_Cz  \\\n",
       "0                                   2.206824   \n",
       "1                                   2.053111   \n",
       "2                                   2.289503   \n",
       "3                                   2.280436   \n",
       "4                                   2.367014   \n",
       "\n",
       "   f1_slope_calc_by_fooof__fooof_f1_slope_F3  \\\n",
       "0                                   1.709732   \n",
       "1                                   1.639974   \n",
       "2                                   1.675787   \n",
       "3                                   1.509626   \n",
       "4                                   1.712145   \n",
       "\n",
       "   f1_slope_calc_by_fooof__fooof_f1_slope_F4  \\\n",
       "0                                   1.561775   \n",
       "1                                   1.484552   \n",
       "2                                   1.777413   \n",
       "3                                   1.535515   \n",
       "4                                   1.611813   \n",
       "\n",
       "   f1_slope_calc_by_fooof__fooof_f1_slope_F7  \\\n",
       "0                                   1.748864   \n",
       "1                                   1.865091   \n",
       "2                                   2.115215   \n",
       "3                                   1.883346   \n",
       "4                                   2.106452   \n",
       "\n",
       "   f1_slope_calc_by_fooof__fooof_f1_slope_F8  \\\n",
       "0                                   2.085033   \n",
       "1                                   2.075424   \n",
       "2                                   2.103583   \n",
       "3                                   1.669940   \n",
       "4                                   1.933161   \n",
       "\n",
       "   f1_slope_calc_by_fooof__fooof_f1_slope_Fp1  \\\n",
       "0                                    1.406818   \n",
       "1                                    1.535537   \n",
       "2                                    1.611884   \n",
       "3                                    1.504872   \n",
       "4                                    1.927252   \n",
       "\n",
       "   f1_slope_calc_by_fooof__fooof_f1_slope_Fp2  \\\n",
       "0                                    2.111207   \n",
       "1                                    1.643439   \n",
       "2                                    1.952839   \n",
       "3                                    1.948231   \n",
       "4                                    2.323573   \n",
       "\n",
       "   f1_slope_calc_by_fooof__fooof_f1_slope_Fz  \\\n",
       "0                                   1.721701   \n",
       "1                                   1.879024   \n",
       "2                                   2.041131   \n",
       "3                                   1.960013   \n",
       "4                                   2.080833   \n",
       "\n",
       "   f1_slope_calc_by_fooof__fooof_f1_slope_O1  \\\n",
       "0                                   2.125500   \n",
       "1                                   2.045097   \n",
       "2                                   2.030921   \n",
       "3                                   1.991852   \n",
       "4                                   2.300203   \n",
       "\n",
       "   f1_slope_calc_by_fooof__fooof_f1_slope_O2  \\\n",
       "0                                   2.083735   \n",
       "1                                   2.077167   \n",
       "2                                   2.158749   \n",
       "3                                   2.038563   \n",
       "4                                   2.282525   \n",
       "\n",
       "   f1_slope_calc_by_fooof__fooof_f1_slope_P3  \\\n",
       "0                                   2.376242   \n",
       "1                                   2.097744   \n",
       "2                                   2.005443   \n",
       "3                                   2.033714   \n",
       "4                                   2.352912   \n",
       "\n",
       "   f1_slope_calc_by_fooof__fooof_f1_slope_P4  \\\n",
       "0                                   1.939174   \n",
       "1                                   2.083318   \n",
       "2                                   2.240399   \n",
       "3                                   2.051334   \n",
       "4                                   2.373809   \n",
       "\n",
       "   f1_slope_calc_by_fooof__fooof_f1_slope_Pz  \\\n",
       "0                                   1.996931   \n",
       "1                                   2.018160   \n",
       "2                                   2.291582   \n",
       "3                                   2.192498   \n",
       "4                                   2.380740   \n",
       "\n",
       "   f1_slope_calc_by_fooof__fooof_f1_slope_T3  \\\n",
       "0                                   1.551694   \n",
       "1                                   1.818997   \n",
       "2                                   1.927433   \n",
       "3                                   2.055290   \n",
       "4                                   2.283877   \n",
       "\n",
       "   f1_slope_calc_by_fooof__fooof_f1_slope_T4  \\\n",
       "0                                   1.725685   \n",
       "1                                   1.988955   \n",
       "2                                   2.018851   \n",
       "3                                   1.902660   \n",
       "4                                   1.669275   \n",
       "\n",
       "   f1_slope_calc_by_fooof__fooof_f1_slope_T5  \\\n",
       "0                                   2.056437   \n",
       "1                                   2.066521   \n",
       "2                                   1.901319   \n",
       "3                                   1.941317   \n",
       "4                                   2.264911   \n",
       "\n",
       "   f1_slope_calc_by_fooof__fooof_f1_slope_T6  \n",
       "0                                   1.806958  \n",
       "1                                   2.147957  \n",
       "2                                   2.200489  \n",
       "3                                   1.961843  \n",
       "4                                   2.123244  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview y_ser (A->0, C->1):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Meta (subject windows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>window_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub-002</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub-002</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub-002</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id  window_idx\n",
       "0        sub-002           0\n",
       "1        sub-002           1\n",
       "2        sub-002           2\n",
       "3        sub-002           3\n",
       "4        sub-002           4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_participants = pd.read_csv(\"participants.tsv\", sep='\\t')\n",
    "\n",
    "# Build X/y from *your* notebook data:\n",
    "FEATURES = \"f1_slope_calc_by_fooof\" #[\"plv\", \"bands_rel\", \"bands_abs\", \"mean_std\"]\n",
    "\n",
    "X_df, y_ser, meta, used_channels, _cfg = load_extracted_features(FEATURES)\n",
    "\n",
    "print(\"\\nPreview X_df:\")\n",
    "display(X_df.head())\n",
    "print(\"\\nPreview y_ser (A->0, C->1):\")\n",
    "display(y_ser.head())\n",
    "print(\"\\nMeta (subject windows):\")\n",
    "display(meta.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a010864-43af-4f38-bcc5-b201d7ec1567",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train windows: 41713 | Test windows: 11437\n",
      "Train label counts: {0: 22776, 1: 18937}\n",
      "Test  label counts: {0: 6305, 1: 5132}\n",
      "Train subjects: 52 | Test subjects: 13\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# === Subject-wise 80/20 train-test split ===\n",
    "# ensures that participants (subjects) are not mixed between train/test\n",
    "assert \"participant_id\" in meta.columns, \"meta must contain 'participant_id'.\"\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, test_idx = next(gss.split(X_df, y_ser, groups=meta['participant_id']))\n",
    "\n",
    "# build the splits\n",
    "X_train = X_df.iloc[train_idx].reset_index(drop=True)\n",
    "y_train = y_ser.iloc[train_idx].reset_index(drop=True)\n",
    "meta_train = meta.iloc[train_idx].reset_index(drop=True)\n",
    "\n",
    "X_test  = X_df.iloc[test_idx].reset_index(drop=True)\n",
    "y_test  = y_ser.iloc[test_idx].reset_index(drop=True)\n",
    "meta_test = meta.iloc[test_idx].reset_index(drop=True)\n",
    "\n",
    "print(f\"Train windows: {len(X_train)} | Test windows: {len(X_test)}\")\n",
    "print(\"Train label counts:\", y_train.value_counts().to_dict())\n",
    "print(\"Test  label counts:\", y_test.value_counts().to_dict())\n",
    "print(\"Train subjects:\", meta_train['participant_id'].nunique(),\n",
    "      \"| Test subjects:\", meta_test['participant_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f4017e4-6727-4e04-909e-2f0f9d695d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNNTrainer:\n",
    "    def __init__(self, X_df, y_ser, device=None, random_state=42):\n",
    "        self.device = torch.device(device or (\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        # labels\n",
    "        y = y_ser\n",
    "        if y.dtype.kind not in \"iu\":\n",
    "            y = y.astype(str).str.upper().map({\"A\": 0, \"C\": 1})\n",
    "        self.y_np = y.to_numpy()\n",
    "\n",
    "        # features\n",
    "        self.X_np = X_df.to_numpy(dtype=np.float32)\n",
    "        assert np.isfinite(self.X_np).all()\n",
    "\n",
    "        print(f\"Using device: {self.device}\")\n",
    "\n",
    "    def _prep_data(self, use_smote=True):\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(self.X_np).astype(np.float32)\n",
    "        self.scaler_ = scaler\n",
    "\n",
    "        if use_smote:\n",
    "            smote = SMOTE(random_state=self.random_state)\n",
    "            X_res, y_res = smote.fit_resample(X_scaled, self.y_np)\n",
    "        else:\n",
    "            X_res, y_res = X_scaled, self.y_np\n",
    "\n",
    "        return (\n",
    "            torch.tensor(X_res, dtype=torch.float32),\n",
    "            torch.tensor(y_res, dtype=torch.long),\n",
    "            scaler\n",
    "        )\n",
    "\n",
    "    def _encode_to_spikes(self, x, num_steps, method=\"rate\", gain=0.3):\n",
    "        return encode_to_spikes_eval(x, num_steps, method, gain)\n",
    "\n",
    "    def train(self, num_epochs=50, batch_size=32, hidden_size=64,\n",
    "              num_steps=25, beta=0.7, lr=1e-3,\n",
    "              encoding_method=\"rate\", use_smote=True,\n",
    "              save_prefix=\"./eeg_snn\"):\n",
    "\n",
    "        X_t, y_t, scaler = self._prep_data(use_smote)\n",
    "        dataset = torch.utils.data.TensorDataset(X_t, y_t)\n",
    "        loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        self.cfg_ = {\"num_steps\": num_steps, \"encoding_method\": encoding_method}\n",
    "        model = SNNModel(X_t.shape[1], hidden_size, 2, beta=beta, num_steps=num_steps).to(self.device)\n",
    "        self.model_ = model\n",
    "\n",
    "        opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        print(f\"Starting SNN training (encoding={encoding_method})...\")\n",
    "\n",
    "        for epoch in range(1, num_epochs + 1):\n",
    "            model.train()\n",
    "            epoch_loss = 0\n",
    "\n",
    "            for xb, yb in loader:\n",
    "                xb, yb = xb.to(self.device), yb.to(self.device)\n",
    "                \n",
    "                spikes = self._encode_to_spikes(xb, num_steps, encoding_method).to(self.device)\n",
    "                spk_rec, _ = model(spikes)\n",
    "\n",
    "                out = spk_rec.sum(0)\n",
    "\n",
    "                loss = loss_fn(out, yb)\n",
    "                opt.zero_grad()\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "            if epoch % 10 == 0 or epoch == 1 or epoch == num_epochs:\n",
    "                acc = self.evaluate(model, X_t, y_t, encoding_method, num_steps)\n",
    "                avg_loss = epoch_loss / len(loader)\n",
    "                print(f\"Epoch {epoch:03d} | avg_loss={avg_loss:.4f} | acc={acc:.4f}\")\n",
    "\n",
    "        torch.save(model.state_dict(), f\"{save_prefix}_model.pt\")\n",
    "        joblib.dump(scaler, f\"{save_prefix}_scaler.pkl\")\n",
    "        print(f\"Saved model -> {save_prefix}_model.pt ; scaler -> {save_prefix}_scaler.pkl\")\n",
    "\n",
    "        return model\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def evaluate(self, model, X_all, y_all, encoding_method, num_steps):\n",
    "        model.eval()\n",
    "        spikes = self._encode_to_spikes(X_all.to(self.device), num_steps, encoding_method)\n",
    "        spk_rec, _ = model(spikes)\n",
    "        out = spk_rec.sum(0)\n",
    "        pred = out.argmax(1)\n",
    "        return (pred == y_all.to(self.device)).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c275de57-ed89-4437-bc00-eb67026cea1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Starting SNN training (encoding=rate)...\n",
      "Epoch 001 | avg_loss=0.6230 | acc=0.7006\n",
      "Epoch 010 | avg_loss=0.4982 | acc=0.7582\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m HIDDEN_SIZE = \u001b[32m128\u001b[39m\n\u001b[32m     10\u001b[39m NUM_EPOCHS = \u001b[32m50\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m model = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mHIDDEN_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mNUM_STEPS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBETA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mLEARNING_RATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCODING_METHOD\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_smote\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./eeg_snn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     22\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m scaler = trainer.scaler_\n\u001b[32m     25\u001b[39m model  = trainer.model_\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 64\u001b[39m, in \u001b[36mSNNTrainer.train\u001b[39m\u001b[34m(self, num_epochs, batch_size, hidden_size, num_steps, beta, lr, encoding_method, use_smote, save_prefix)\u001b[39m\n\u001b[32m     61\u001b[39m xb, yb = xb.to(\u001b[38;5;28mself\u001b[39m.device), yb.to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m     63\u001b[39m spikes = \u001b[38;5;28mself\u001b[39m._encode_to_spikes(xb, num_steps, encoding_method).to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m spk_rec, _ = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspikes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m out = spk_rec.sum(\u001b[32m0\u001b[39m)\n\u001b[32m     68\u001b[39m loss = loss_fn(out, yb)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/EEG/upload to Ebrains/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/EEG/upload to Ebrains/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mSNNModel.forward\u001b[39m\u001b[34m(self, x_TBF)\u001b[39m\n\u001b[32m     42\u001b[39m spk2, mem2 = \u001b[38;5;28mself\u001b[39m.lif2(cur2, mem2)\n\u001b[32m     44\u001b[39m cur3 = \u001b[38;5;28mself\u001b[39m.fc3(spk2)        \u001b[38;5;66;03m# [B,C]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m spk3, mem3 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlif3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmem3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m spk3_rec.append(spk3)\n\u001b[32m     48\u001b[39m mem3_rec.append(mem3)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/EEG/upload to Ebrains/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/EEG/upload to Ebrains/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/EEG/upload to Ebrains/venv/lib/python3.12/site-packages/snntorch/_neurons/leaky.py:209\u001b[39m, in \u001b[36mLeaky.forward\u001b[39m\u001b[34m(self, input_, mem)\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mem.shape == input_.shape:\n\u001b[32m    207\u001b[39m     \u001b[38;5;28mself\u001b[39m.mem = torch.zeros_like(input_, device=\u001b[38;5;28mself\u001b[39m.mem.device)\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m \u001b[38;5;28mself\u001b[39m.reset = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmem_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[38;5;28mself\u001b[39m.mem = \u001b[38;5;28mself\u001b[39m.state_function(input_)\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state_quant:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/EEG/upload to Ebrains/venv/lib/python3.12/site-packages/snntorch/_neurons/neurons.py:106\u001b[39m, in \u001b[36mSpikingNeuron.mem_reset\u001b[39m\u001b[34m(self, mem)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Generates detached reset signal if mem > threshold.\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[33;03mReturns reset.\"\"\"\u001b[39;00m\n\u001b[32m    105\u001b[39m mem_shift = mem - \u001b[38;5;28mself\u001b[39m.threshold\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m reset = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mspike_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmem_shift\u001b[49m\u001b[43m)\u001b[49m.clone().detach()\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m reset\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/EEG/upload to Ebrains/venv/lib/python3.12/site-packages/snntorch/surrogate.py:151\u001b[39m, in \u001b[36mfast_sigmoid.<locals>.inner\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(x):\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFastSigmoid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslope\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/EEG/upload to Ebrains/venv/lib/python3.12/site-packages/torch/autograd/function.py:581\u001b[39m, in \u001b[36mFunction.apply\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch._C._are_functorch_transforms_active():\n\u001b[32m    579\u001b[39m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[32m    580\u001b[39m     args = _functorch.utils.unwrap_dead_wrappers(args)\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m    583\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[32m    584\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    585\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    586\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    587\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstaticmethod. For more details, please see \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    588\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    589\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/EEG/upload to Ebrains/venv/lib/python3.12/site-packages/snntorch/surrogate.py:135\u001b[39m, in \u001b[36mFastSigmoid.forward\u001b[39m\u001b[34m(ctx, input_, slope)\u001b[39m\n\u001b[32m    133\u001b[39m ctx.save_for_backward(input_)\n\u001b[32m    134\u001b[39m ctx.slope = slope\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m out = \u001b[43m(\u001b[49m\u001b[43minput_\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "trainer = SNNTrainer(X_df, y_ser)\n",
    "\n",
    "set_global_seed(42)\n",
    "# pick one: \"rate\" or \"latency\"\n",
    "CODING_METHOD = \"rate\"\n",
    "BETA = 0.5\n",
    "LEARNING_RATE = 5e-4\n",
    "NUM_STEPS = 40\n",
    "HIDDEN_SIZE = 128\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "model = trainer.train(\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    batch_size=64,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_steps=NUM_STEPS,\n",
    "    beta=BETA,\n",
    "    lr=LEARNING_RATE,\n",
    "    encoding_method=CODING_METHOD,\n",
    "    use_smote=True,\n",
    "    save_prefix=\"./eeg_snn\"\n",
    ")\n",
    "\n",
    "scaler = trainer.scaler_\n",
    "model  = trainer.model_\n",
    "cfg    = trainer.cfg_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aaa49f-286c-412f-8bc6-67cecb600511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Validation (window- and subject-level) ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, balanced_accuracy_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1) Scale test features with loaded scaler (if any)\n",
    "X_test_scaled = scaler.transform(X_test.values).astype(\"float32\")\n",
    "X_test_t = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "\n",
    "# 2) Inference: logits [N, C]\n",
    "logits = infer_logits_batched(\n",
    "    model,\n",
    "    X_test_t,\n",
    "    batch_size=128,\n",
    "    encoding_method=cfg[\"encoding_method\"],\n",
    "    num_steps=cfg[\"num_steps\"],\n",
    "    device=trainer.device,\n",
    ")\n",
    "y_pred = logits.argmax(dim=1).cpu().numpy()\n",
    "y_true = np.asarray(y_test)\n",
    "\n",
    "label_names = [\"A\", \"C\"]  # 0 -> A, 1 -> C\n",
    "\n",
    "# ---------- Model config ----------\n",
    "print(\"\\n=== Model config ===\")\n",
    "print(f'CODING: {CODING_METHOD} LEARNING RATE: {LEARNING_RATE} BETA: {BETA}')\n",
    "print(f'NUM_STEPS: {NUM_STEPS} HIDDEN_SIZE: {HIDDEN_SIZE} NUM_EPOCHS: {NUM_EPOCHS}')\n",
    "print(f'FEATURES: {FEATURES}')\n",
    "# ---------- Window-level ----------\n",
    "print(\"\\n=== Window-level ===\")\n",
    "acc_win = accuracy_score(y_true, y_pred)\n",
    "bal_win = balanced_accuracy_score(y_true, y_pred)\n",
    "f1m_win  = f1_score(y_true, y_pred, average=\"macro\")\n",
    "print(f\"Accuracy: {acc_win:.4f}\")\n",
    "print(f\"Balanced Accuracy: {bal_win:.4f}\")\n",
    "print(f\"Macro F1: {f1m_win:.4f}\")\n",
    "\n",
    "cm_win = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "print(\"\\nConfusion matrix (rows=true A,C; cols=pred A,C):\\n\", cm_win)\n",
    "\n",
    "print(\"\\nClassification report:\\n\",\n",
    "      classification_report(y_true, y_pred, target_names=label_names, digits=4))\n",
    "\n",
    "# ---------- Subject-level majority vote with logit tie-break ----------\n",
    "df_pred = meta_test.copy()\n",
    "df_pred[\"y_true\"] = y_true\n",
    "df_pred[\"y_pred\"] = y_pred\n",
    "logits_np = logits.detach().cpu().numpy()\n",
    "for c in range(logits_np.shape[1]):\n",
    "    df_pred[f\"logit_{c}\"] = logits_np[:, c]\n",
    "\n",
    "def _mode_strict(s: pd.Series) -> int:\n",
    "    vc = s.value_counts()\n",
    "    winners = sorted(vc[vc == vc.max()].index.tolist())\n",
    "    return int(winners[0])\n",
    "\n",
    "def _vote_with_logit_tiebreak(g: pd.DataFrame) -> int:\n",
    "    vc = g[\"y_pred\"].value_counts()\n",
    "    winners = vc[vc == vc.max()].index.tolist()\n",
    "    if len(winners) == 1:\n",
    "        return int(winners[0])\n",
    "    sums = {cls: g[f\"logit_{cls}\"].sum() for cls in winners}\n",
    "    best = max(sums.values())\n",
    "    winners2 = [cls for cls, s in sums.items() if np.isclose(s, best)]\n",
    "    return int(min(winners2))\n",
    "\n",
    "subj = df_pred.groupby(\"participant_id\").apply(\n",
    "    lambda g: pd.Series({\n",
    "        \"y_true\": _mode_strict(g[\"y_true\"]),\n",
    "        \"y_pred\": _vote_with_logit_tiebreak(g),\n",
    "        \"n_windows\": len(g)\n",
    "    })\n",
    ").reset_index()\n",
    "\n",
    "print(\"\\n=== Subject-level ===\")\n",
    "acc_subj = accuracy_score(subj[\"y_true\"], subj[\"y_pred\"])\n",
    "bal_subj = balanced_accuracy_score(subj[\"y_true\"], subj[\"y_pred\"])\n",
    "f1m_subj = f1_score(subj[\"y_true\"], subj[\"y_pred\"], average=\"macro\")\n",
    "print(f\"Subject Accuracy: {acc_subj:.4f}\")\n",
    "print(f\"Subject Balanced Accuracy: {bal_subj:.4f}\")\n",
    "print(f\"Subject Macro F1: {f1m_subj:.4f}\")\n",
    "\n",
    "cm_subj = confusion_matrix(subj[\"y_true\"], subj[\"y_pred\"], labels=[0, 1])\n",
    "print(\"\\nSubject-level confusion matrix (rows=true A,C; cols=pred A,C):\\n\", cm_subj)\n",
    "\n",
    "# Pretty table\n",
    "cm_df = pd.DataFrame(cm_subj, index=[\"True A\", \"True C\"], columns=[\"Pred A\", \"Pred C\"])\n",
    "display(cm_df)\n",
    "\n",
    "# ---------- Optional: Matplotlib confusion matrices ----------\n",
    "def plot_cm(cm, title=\"Confusion Matrix\", ticklabels=(\"A\",\"C\")):\n",
    "    plt.figure(figsize=(5,4))\n",
    "    plt.imshow(cm, interpolation=\"nearest\")\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    ticks = np.arange(len(ticklabels))\n",
    "    plt.xticks(ticks, ticklabels)\n",
    "    plt.yticks(ticks, ticklabels)\n",
    "    thresh = cm.max() / 2.0 if cm.max() > 0 else 0.5\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], \"d\"),\n",
    "                     ha=\"center\", va=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_cm(cm_win,  title=\"Window-level Confusion Matrix\",  ticklabels=label_names)\n",
    "plot_cm(cm_subj, title=\"Subject-level Confusion Matrix\", ticklabels=label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc8a7b8-80bb-4101-a592-0b810b831544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_snn_for_spinnaker(\n",
    "    model,\n",
    "    scaler=None,\n",
    "    cfg=None,\n",
    "    beta=None,\n",
    "    out_dir: str = \"./spinnaker_export\"\n",
    "):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    model_cpu = model.to(\"cpu\").eval()\n",
    "\n",
    "    fc1_W = model_cpu.fc1.weight.detach().numpy()  # [H1, F]\n",
    "    fc1_b = model_cpu.fc1.bias.detach().numpy()    # [H1]\n",
    "\n",
    "    fc2_W = model_cpu.fc2.weight.detach().numpy()  # [H2, H1]\n",
    "    fc2_b = model_cpu.fc2.bias.detach().numpy()    # [H2]\n",
    "\n",
    "    fc3_W = model_cpu.fc3.weight.detach().numpy()  # [C, H2]\n",
    "    fc3_b = model_cpu.fc3.bias.detach().numpy()    # [C]\n",
    "\n",
    "    np.save(os.path.join(out_dir, \"fc1_W.npy\"), fc1_W)\n",
    "    np.save(os.path.join(out_dir, \"fc1_b.npy\"), fc1_b)\n",
    "    np.save(os.path.join(out_dir, \"fc2_W.npy\"), fc2_W)\n",
    "    np.save(os.path.join(out_dir, \"fc2_b.npy\"), fc2_b)\n",
    "    np.save(os.path.join(out_dir, \"fc3_W.npy\"), fc3_W)\n",
    "    np.save(os.path.join(out_dir, \"fc3_b.npy\"), fc3_b)\n",
    "\n",
    "    meta = {\n",
    "        \"input_size\": int(fc1_W.shape[1]),\n",
    "        \"hidden1_size\": int(fc1_W.shape[0]),\n",
    "        \"hidden2_size\": int(fc2_W.shape[0]),\n",
    "        \"output_size\": int(fc3_W.shape[0]),\n",
    "    }\n",
    "\n",
    "    if cfg is not None:\n",
    "        meta[\"num_steps\"] = int(cfg.get(\"num_steps\", -1))\n",
    "        meta[\"encoding_method\"] = str(cfg.get(\"encoding_method\", \"rate\"))\n",
    "\n",
    "    if beta is not None:\n",
    "        meta[\"beta\"] = float(beta)\n",
    "\n",
    "    meta_path = os.path.join(out_dir, \"meta.json\")\n",
    "    with open(meta_path, \"w\") as f:\n",
    "        json.dump(meta, f, indent=2)\n",
    "\n",
    "    if scaler is not None:\n",
    "        scaler_path = os.path.join(out_dir, \"scaler.pkl\")\n",
    "        joblib.dump(scaler, scaler_path)\n",
    "\n",
    "    print(\"Exported SNN for SpiNNaker to:\", out_dir)\n",
    "    print(\"  - fc1_W.npy, fc1_b.npy\")\n",
    "    print(\"  - fc2_W.npy, fc2_b.npy\")\n",
    "    print(\"  - fc3_W.npy, fc3_b.npy\")\n",
    "    print(\"  - meta.json\")\n",
    "    if scaler is not None:\n",
    "        print(\"  - scaler.pkl\")\n",
    "\n",
    "export_snn_for_spinnaker(\n",
    "    model,\n",
    "    scaler=scaler,\n",
    "    cfg=cfg,\n",
    "    beta=BETA,\n",
    "    out_dir=\"./spinnaker_export\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
